/*************************************************************************************************

Welcome to Baml! To use this generated code, please run one of the following:

$ npm install @boundaryml/baml
$ yarn add @boundaryml/baml
$ pnpm add @boundaryml/baml

*************************************************************************************************/

// This file was generated by BAML: do not edit it. Instead, edit the BAML
// files and re-generate this code.
//
/* eslint-disable */
// tslint:disable
// @ts-nocheck
// biome-ignore format: autogenerated code
const fileMap = {
  
  "chat.baml": "\nclass BamlChatThread {\n    events Event[]\n}\n\nclass Event {\n    type AllowedTypes\n    data (UserInput | AssisantMessage | UpdateEstimateRequest | UpdateEstimateResponse)\n}\n\n// Event Types\nenum AllowedTypes {\n    UserInput\n    AssisantMessage\n    UpdateEstimateRequest\n    UpdateEstimateResponse\n}\n\nclass UserInput {\n    message string @description(\"The message from the user\")\n}\n\nclass AssisantMessage {\n    message string @description(\"The message from the assistant\")\n}\n\n\nclass UpdateEstimateRequest {\n    changes_to_make string @description(\"Detailed description of changes to make to the estimate\")\n}\n\nclass UpdateEstimateResponse {\n    success bool @description(\"Whether the update was successful\")\n    error_message string @description(\"The error message if the update was not successful\")\n}\n\n\nfunction DetermineNextStep(thread: BamlChatThread, current_estimate: ConstructionProjectData) -> Event {\n    client OpenaiFallback\n    prompt #\"\n    You're a construction estimator working with a client. Help the client with any questions including updating the estimate as needed.\n    Use the current estimate and the conversation history to determine the next step.\n\n    <current_estimate>\n    {{ current_estimate }}\n    </current_estimate>\n\n    <conversation_history>\n    {% for event in thread.events %}\n    <{{ event.type }}>\n    {{ event.data }}\n    </{{ event.type }}>\n    {% endfor %}\n    </conversation_history>\n    {{ ctx.output_format }}\n    \"#\n    \n}\n\n\ntest TestDetermineNextStep {\n    functions [DetermineNextStep]\n    args {\n        thread {\n            events [\n                {\n                    type \"UserInput\"\n                    data {\n                        message \"Hello, how are you?\"\n                    }\n                }\n            ]\n        }\n    }\n}",
  "clients.baml": "// https://docs.boundaryml.com/docs/snippets/clients/fallback\nclient<llm> OpenaiFallback {\n  provider fallback\n  options {\n    // This will try the clients in order until one succeeds\n    strategy [GPT41MiniWith2Retries, GPT41With2Retries]\n  }\n}\n\n// Learn more about clients at https://docs.boundaryml.com/docs/snippets/clients/overview\nclient<llm> LocalQwen3 {\n  provider \"openai-generic\"\n  options {\n    base_url \"http://localhost:1234/v1\"\n    model \"qwen3-8b-mlx\"\n  }\n}\n\n// Step 2b: Define BAML Clients\nclient<llm> GeminiProcessor {\n  provider google-ai\n  options {\n    // Pull model name from env or keep configurable if needed\n    model \"gemini-2.5-flash-preview-04-17\"\n    api_key env.GOOGLE_API_KEY\n\n  }\n}\n\nclient<llm> O4Mini {\n  provider openai\n  options {\n    model \"o4-mini-2025-04-16\"\n    api_key env.OPENAI_API_KEY\n  }\n}\n\nclient<llm> GPT41With2Retries {\n  provider openai\n  retry_policy Exponential\n  options {\n    model \"gpt-4.1\"\n    api_key env.OPENAI_API_KEY\n  }\n}\n\nclient<llm> GPT41MiniWith2Retries {\n  provider openai\n  retry_policy Exponential\n  options {\n    model \"gpt-4.1-mini\"\n    api_key env.OPENAI_API_KEY\n  }\n}\n\n// https://docs.boundaryml.com/docs/snippets/clients/retry\nretry_policy Exponential {\n  max_retries 2\n  // Strategy is optional\n  strategy {\n    type exponential_backoff\n    delay_ms 300\n    multiplier 1.5\n    max_delay_ms 10000\n  }\n}",
  "file_processor.baml": "// BAML file: apps/langgraph/src/file_processor/baml_src/file_processor.baml\n\nclass EstimateLineItem {\n  description string @description(\"Description of the work item or material\")\n  category string @description(\"Category of the item (e.g., Demo, Plumbing, Electrical, etc.)\")\n  subcategory string? @description(\"Subcategory for further classification\")\n  cost_range_min float @description(\"Minimum estimated cost in dollars\")\n  cost_range_max float @description(\"Maximum estimated cost in dollars\")\n  unit string? @description(\"Unit of measurement (e.g., hours, sq ft, linear ft)\")\n  quantity float? @description(\"Estimated quantity\")\n  assumptions string? @description(\"Key assumptions made for this line item\")\n  confidence_score string? @description(\"Confidence in the estimate based on the information provided: (High, Medium, Low)\")\n  notes string? @description(\"Additional notes or details\")\n}\n\nclass ConstructionProjectData {\n  project_description string @description(\"Brief summary of the project scope\")\n  estimated_total_min float? @description(\"Minimum total estimated cost\")\n  estimated_total_max float? @description(\"Maximum total estimated cost\")\n  estimated_timeline_days int? @description(\"Estimated project duration in days\")\n  key_considerations string[] @description(\"List of key considerations for this project\")\n  confidence_level string @description(\"Overall confidence level in the estimate (High, Medium, Low)\")\n  estimate_items EstimateLineItem[] @description(\"Line items for the estimate\")\n  next_steps string[] @description(\"Prioritized next steps for the contractor\")\n  missing_information string[] @description(\"Information needed to improve estimate accuracy\")\n  key_risks string[] @description(\"List of key risks or potential complications\")\n}\n\nclass InputFile {\n  name string\n  type string // \"image\", \"video\", \"audio\", \"text\"\n  description string? // Optional description\n  content string?     // Text content or transcription\n  download_url string? // URL to download the file content\\\n  image_data image? // Optional image data https://docs.boundaryml.com/ref/baml/types#image\n  audio_data audio? // Optional audio data https://docs.boundaryml.com/ref/baml/types#audio\n}\n\nclass VideoFrame {\n  timestamp float @description(\"Timestamp of the frame in seconds\")\n  description string @description(\"Detailed description of the frame and its relevance to the project\")\n}\n\nclass ProcessedVideo {\n  summary string @description(\"Summary of the video content with details about how each frame contributes to the project\")\n  frames VideoFrame[] @description(\"A list of frames that are cover all of the details from the video\")\n}\n\nfunction GenerateProjectEstimate(files: InputFile[], existing_estimate: ConstructionProjectData?, requested_changes: string?) -> ConstructionProjectData {\n  client OpenaiFallback\n  prompt #\"\n  You are an AI assistant specialized in analyzing construction project documents and media.\n  Your task is to synthesize information from various sources (text files, image descriptions, audio transcriptions)\n  and generate a structured cost estimate for a construction project.\n  Focus on extracting key details relevant to scope, materials, potential issues, or requirements mentioned in the files.\n\n  <UserProvidedFiles>\n  {% for file in files %}\n  <file name={{ file.name }} type={{ file.type }} description={{ file.description }}>\n  {% if file.image_data %}\n  {{ file.image_data }}\n  {% else %}\n  {{ file.content }}\n  {% endif %}\n  </file>\n  {% endfor %}\n  </UserProvidedFiles>\n\n  {% if existing_estimate %}\n  <ExistingEstimate>\n  {{ existing_estimate }}\n  </ExistingEstimate>\n  {% endif %}\n\n  {% if requested_changes %}\n  The user has requested the following changes to the existing estimate:\n  <RequestedChanges>\n  {{ requested_changes }}\n  </RequestedChanges>\n  {% endif %}\n\n  Based *solely* on the provided information, generate a detailed estimate including a project description, total estimated cost, and a list of line items with their individual costs.\n  Output the estimate as a JSON object conforming to the specified schema.\n\n  {{ ctx.output_format }}\n  \"#\n}\n\ntest TestGenerateProjectEstimate {\n  functions [GenerateProjectEstimate]\n  args {\n    files [\n      {name \"measurements.txt\", type \"text\", description \"measurements of the bathroom\", content \"10x10\"},\n      {name \"existing_bathroom.jpg\", type \"image\", description \"existing bathroom\", image_data {\n        file \"../apps/langgraph/tests/testdata/dated-bathroom.png\"\n      }},\n    ]\n  }\n}\n\n\nfunction ProcessVideo(video: InputFile) -> ProcessedVideo {\n  client GeminiProcessor\n  prompt #\"\n    You're an expert construction estimator. You're given a video of a construction project.\n    Your task is to review the video and provide a summary of the project.\n\n   {{ ctx.output_format }}\n  \"#\n\n}\n\nfunction ProcessAudio(audio: InputFile) -> string {\n  client GeminiProcessor\n  prompt #\"\n    You're an expert construction estimator. You're given an audio file of a construction project.\n    Your task is to review the audio and provide a transcription of the audio.\n\n    <Audio>\n    {{ audio.audio_data }}\n    </Audio>\n\n    Output the transcription as a string.\n\n  \"#\n}\n\ntest TestProcessAudio {\n  functions [ProcessAudio]\n  args {\n    audio {\n      name \"walkthrough_notes.m4a\", type \"audio\", description \"walkthrough notes\", audio_data {\n        file \"../apps/web/supabase/storage_seed_files/contractor-app-dev/project2/walkthrough_notes.m4a\"\n      }\n    }\n  }\n}",
  "generators.baml": "generator ts_client {\n  output_type        \"typescript/react\"\n  output_dir         \"../apps/web/baml_client\"\n  version            \"0.86.1\"\n  default_client_mode async\n}\n\ngenerator py_client {\n  output_type        \"python/pydantic\"\n  output_dir         \"../apps/langgraph/src/file_processor\"\n  version            \"0.86.1\"\n  default_client_mode async\n}",
}
export const getBamlFiles = () => {
    return fileMap;
}